{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efedba35-341d-461d-9d52-7c75ae2bafbf",
   "metadata": {},
   "source": [
    "**Programador preterminado dask**\n",
    "    \n",
    "**Threads vs. processes**\n",
    "\n",
    "*Thredas (Hilos) :*\n",
    "\n",
    "    - Dask arrays\n",
    "    - Dask dataframes\n",
    "    - Delayed pipelines creados con dask.delayed()\n",
    "    - Son muy rápidos para inicia\n",
    "    - No es necesario transferirles datos\n",
    "    - Están limitados por el GIL, lo que permite que un subproceso lea el código de una sola vez\n",
    "    \n",
    "*Processes (Procesos) :*\n",
    "    \n",
    "    - Dask bags\n",
    "    - Tómese el tiempo para configurar\n",
    "    - Lento para transferir datos\n",
    "    - Cada uno tiene su propio GIL, por lo que no es necesario turnarse para leer el código\n",
    "\n",
    "*Elegir el programador*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b020c57c-55c3-4176-81e1-0a116d0b4fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import dask\n",
    "\n",
    "df  = dd.read_csv(\"spotify/*.csv\", blocksize=\"1MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0184b394-9893-4aa3-ab52-505dd877815f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0       114.0\n",
       " 1       112.0\n",
       " 2       121.0\n",
       " 3       170.0\n",
       " 4       160.0\n",
       "         ...  \n",
       " 5378    120.0\n",
       " 5379    140.0\n",
       " 5380    127.0\n",
       " 5381     90.0\n",
       " 5382     92.0\n",
       " Name: tempo, Length: 161738, dtype: float64,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df[\"tempo\"].round()\n",
    "\n",
    "#Uso normal\n",
    "result = x.compute()\n",
    "result = dask.compute(x)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d3fcafe-7e9a-4108-9074-dde80c68c293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0       114.0\n",
       " 1       112.0\n",
       " 2       121.0\n",
       " 3       170.0\n",
       " 4       160.0\n",
       "         ...  \n",
       " 5378    120.0\n",
       " 5379    140.0\n",
       " 5380    127.0\n",
       " 5381     90.0\n",
       " 5382     92.0\n",
       " Name: tempo, Length: 161738, dtype: float64,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uso de threads (hilos)\n",
    "result = x.compute(scheduler = 'threads')\n",
    "result = dask.compute(x, sheduler = 'threads')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d20d99a-c29d-4024-9c52-b00dec8c7a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0       114.0\n",
       " 1       112.0\n",
       " 2       121.0\n",
       " 3       170.0\n",
       " 4       160.0\n",
       "         ...  \n",
       " 5378    120.0\n",
       " 5379    140.0\n",
       " 5380    127.0\n",
       " 5381     90.0\n",
       " 5382     92.0\n",
       " Name: tempo, Length: 161738, dtype: float64,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use processes\n",
    "result = x.compute(scheduler='processes')\n",
    "result = dask.compute(x, scheduler='processes')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a7d1ae-3ef3-44a6-ba30-987f58fbf7d6",
   "metadata": {},
   "source": [
    "**Clústeres y clientes**\n",
    "\n",
    "Según el hardware de su computadora y el cálculo que está tratando de completar, puede ser más rápido ejecutarlo usando una combinación de subprocesos y procesos.\n",
    "\n",
    "Para ello, debe configurar un clúster local.\n",
    "\n",
    "Hay dos formas de configurar un clúster local que usará Dask.\n",
    "\n",
    "La primera forma es crear el clúster local y pasarlo a un cliente.\n",
    "\n",
    "¡Esto es muy similar a cómo configuraría un cliente para que se ejecute en un grupo de computadoras! \n",
    "\n",
    "La segunda forma es usar el cliente directamente y permitirle crear el clúster local por sí mismo.\n",
    "\n",
    "Este es un atajo que funciona para clústeres locales, pero no para otros tipos de clústeres.\n",
    "\n",
    "Creamos clientes utilizando ambos métodos.\n",
    "\n",
    "Tenga cuidado al crear el clúster y los clientes. Si los configura incorrectamente, su sesión puede expirar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8be780-93f3-463c-9dbc-5f7d49c4df24",
   "metadata": {},
   "source": [
    "**Creación de un cluster local**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "323a8cbe-4b8f-4038-a537-9872d2a975be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LocalCluster(63d35828, 'tcp://127.0.0.1:51446', workers=2, threads=4, memory=39.69 GiB)\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "cluster = LocalCluster(\n",
    "    processes=True,\n",
    "    n_workers=2,\n",
    "    threads_per_worker=2)\n",
    "\n",
    "print(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519870e7-dd1e-4e5d-8498-dae1f91b73b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(\n",
    "    processes=False,\n",
    "    n_workers=2,\n",
    "    threads_per_worker=2)\n",
    "\n",
    "print(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3719605-926e-443a-9df9-974174e2b5dd",
   "metadata": {},
   "source": [
    "**Un cluster simple**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3353c61-bb3c-4bc2-8468-8b7efebcddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(processes=True)\n",
    "\n",
    "print(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178aec18-2493-4a79-ace3-40ab06ba570e",
   "metadata": {},
   "source": [
    "**Creación de un cliente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51b066e3-5aa2-438e-bbf5-145a3f3b725b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: 'tcp://127.0.0.1:51446' processes=2 threads=4, memory=39.69 GiB>\n"
     ]
    }
   ],
   "source": [
    "client = Client(cluster)\n",
    "\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6ceecf-3233-4948-8761-7457327d071c",
   "metadata": {},
   "source": [
    "Uso del cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce0ba6a5-6057-4a80-9ec9-1899ca7eccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = x.compute()\n",
    "result = x.compute(scheduler='threads')\n",
    "result = client.compute(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b1637e3-5f43-4b94-bf04-48ac5e9d81d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>Future: finalize</strong>\n",
       "<span style=\"color: var(--jp-ui-font-color2, gray)\"> status: </span>\n",
       "\n",
       "\n",
       "<span style=\"color: var(--jp-error-color0, black)\">finished</span>,\n",
       "\n",
       "\n",
       "\n",
       "<span style=\"color: var(--jp-ui-font-color2, gray)\"> type:</span> pandas.core.series.Series,\n",
       "\n",
       "\n",
       "<span style=\"color: var(--jp-ui-font-color2, gray)\"> key:</span> finalize-cf31f672400f671f54038bf826501b96"
      ],
      "text/plain": [
       "<Future: finished, type: pandas.core.series.Series, key: finalize-cf31f672400f671f54038bf826501b96>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f91091-66d2-4738-95d0-b82d57b77cfe",
   "metadata": {},
   "source": [
    "### Entrenamiento de modelos machine learning con grandes conjuntos de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a7bc4-94e3-4865-a46a-cb467f2fa454",
   "metadata": {},
   "source": [
    "Usando Dask para entrenar un modelo lineal\n",
    "\n",
    "Dask se puede usar para entrenar modelos de aprendizaje automático en conjuntos de datos que son demasiado grandes para caber en la memoria y le permite distribuir la carga de datos, el preprocesamiento y el entrenamiento en varios subprocesos, procesos e incluso en varias computadoras.\n",
    "\n",
    "Se le asignó la tarea de entrenar un modelo de aprendizaje automático que predecirá la popularidad de las canciones en el conjunto de datos de Spotify.\n",
    "\n",
    "Los datos se cargaran como Dask DataFrames perezosos.\n",
    "\n",
    "Las variables de entrada están disponibles dask_X y contienen algunas columnas numéricas, como el tempo y la capacidad de baile de la canción.\n",
    "\n",
    "Los valores objetivo están disponibles como dask_y y son la puntuación de popularidad de cada canción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bb5b6d-5e9f-472b-9654-483f2dc375c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from dask_ml.wrappers import Incremental\n",
    "\n",
    "# Create a SGDRegressor model\n",
    "model = SGDRegressor()\n",
    "\n",
    "# Wrap the model so that it works with Dask\n",
    "dask_model = Incremental(model, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the wrapped model\n",
    "dask_model.fit(dask_X, dask_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d181fe03-6d00-4dbf-ba98-360cdfeb4303",
   "metadata": {},
   "source": [
    "Cada vez que ejecuta el .fit() método, Dask optimiza el cálculo copiando el modelo en el proceso o subproceso donde se encuentran los datos, en lugar de copiar los datos en el proceso principal que contiene el modelo.\n",
    "\n",
    "Puede llevar mucho tiempo copiar la información y el modelo es mucho más pequeño que el conjunto de datos, por lo que es mucho más eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84829186-6d9a-4de3-ba82-940683b73ef1",
   "metadata": {},
   "source": [
    "**Haciendo predicciones perezosas**\n",
    "\n",
    "El modelo que entrenó la última vez fue bueno, pero podría ser mejor si pasara los datos de entrenamiento unas cuantas veces más.\n",
    "\n",
    "Además, es una pena ver que un buen modelo se desperdicia, por lo que debe usar este para hacer algunas predicciones en un conjunto de datos separado del que entrena.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7974885b-408c-4233-99d1-051fcb6f723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the training data 5 times\n",
    "for i in range(5):\n",
    "\n",
    "    dask_model.partial_fit(dask_X, dask_y)\n",
    "\n",
    "# Use your model to make predictions\n",
    "y_pred_delayed = dask_model.predict(dask_X)\n",
    "\n",
    "# Compute the predictions\n",
    "y_pred_computed = y_pred_delayed.compute()\n",
    "\n",
    "print(y_pred_computed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fac1d9a-85fc-4a62-ad01-ab3e71355ea9",
   "metadata": {},
   "source": [
    "¡Fantástico! Ese es un modelo bien ajustado.\n",
    "\n",
    "Si solo usara el .fit() método 5 veces, su código se ejecutaría, pero no obtendría predicciones más precisas en cada repetición del ciclo.\n",
    "\n",
    "Cuando .fit() se ejecuta, el modelo se restablece a un estado no ajustado y se vuelve a ajustar a los datos, por lo que comienza desde cero cada vez.\n",
    "\n",
    "El uso del .partial_fit() método nos permite retomar el ajuste desde donde lo dejamos y refinar el ajuste del bucle anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f39eb2-6dfa-4838-901b-46f2d3b949f7",
   "metadata": {},
   "source": [
    "### Reprocesando grandes conjuntos de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2541135-bbd4-481a-ac90-7efa21e62794",
   "metadata": {},
   "source": [
    "**Transformación perezosa de datos de entrenamiento**\n",
    "\n",
    "El preprocesamiento de las variables de entrada es un paso vital en el aprendizaje automático y, a menudo, mejorará la precisión del modelo que cree.\n",
    "\n",
    "En el último par de ejercicios, los datos de Spotify fueron preprocesados, pero es importante que sepa cómo hacerlo usted mismo.\n",
    "\n",
    "En este ejercicio, utilizará el StandardScaler() objeto escalador, que transforma las columnas de una matriz para que tengan una media de cero y una desviación estándar de uno.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d782fb94-331f-480b-a3bd-6e5d058a9c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the StandardScaler class\n",
    "from dask_ml.preprocessing import StandardScaler\n",
    "\n",
    "X = dask_df[['duration_ms', 'explicit', 'danceability', 'acousticness', 'instrumentalness', 'tempo']]\n",
    "\n",
    "# Select the target variable\n",
    "y = dask_df['popularity']\n",
    "\n",
    "# Create a StandardScaler object and fit it on X\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "# Transform X\n",
    "X = scaler.transform(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f645ec-2416-44c8-a3e0-f24f9e2102e2",
   "metadata": {},
   "source": [
    "¡Bien hecho! \n",
    "\n",
    "Es posible que haya notado que X sigue siendo un Dask DataFrame incluso después de haber sido transformado.\n",
    "\n",
    "Sin embargo, ya ha tenido que cargar todos los datos X una vez para poder ajustar el archivo scaler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e77907-7a5f-4e71-b0a4-655337db6d97",
   "metadata": {},
   "source": [
    "**División de prueba de tren perezoso**\n",
    "\n",
    "Has transformado las X variables.\n",
    "\n",
    "Ahora necesita terminar su preparación de datos transformando las y variables y dividiendo sus datos en conjuntos de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da734593-287a-49cb-99dc-6fdde6c95f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train_test_split function\n",
    "from dask_ml.model_selection import train_test_split\n",
    "\n",
    "# Rescale the target values\n",
    "y = y / 100\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.2)\n",
    "\n",
    "print(X_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
