{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98956e17-49b0-43fe-b94e-beaada5ddf84",
   "metadata": {},
   "source": [
    "### Evaluación peresoza.\n",
    "\n",
    "La computación paralela utiliza lo que se denomina evaluación \"perezosa\".\n",
    "\n",
    "Esto significa que su marco pondrá en cola conjuntos de transformaciones o cálculos para que estén listos para ejecutarse más tarde, en paralelo.\n",
    "\n",
    "Este es un concepto que encontrará en muchos marcos para computación paralela, incluido Dask.\n",
    "\n",
    "Su marco no evaluará los cálculos solicitados hasta que se le indique explícitamente.\n",
    "\n",
    "Esto difiere de las funciones de evaluación \"ansiosas\", que calculan instantáneamente al ser llamadas.\n",
    "\n",
    "Muchas funciones muy comunes y útiles están portadas para ser nativas en Dask, lo que significa que serán perezosas (cálculo retrasado) sin que tengas que preguntar.\n",
    "\n",
    "Sin embargo, a veces tendrá un código personalizado complicado que está escrito en pandas, scikit-learn o incluso base python, que no está disponible de forma nativa en Dask.\n",
    "\n",
    "Otras veces, es posible que simplemente no tenga el tiempo o la energía para refactorizar su código en Dask, si se necesitan ediciones para aprovechar los elementos nativos de Dask.\n",
    "\n",
    "Si este es el caso, puede decorar sus funciones con **@dask.delayed**, que establecerá manualmente que la función debe ser perezosa y no evaluará hasta que se lo indique.\n",
    "\n",
    "Lo diría con los procesos **.compute()** o **.persist()**, descritos en la siguiente sección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dad5070e-e76b-4777-bb1d-f982de8342af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def exponente(x, y): \n",
    "    '''Define una función básica.''' \n",
    "    return x ** y\n",
    "\n",
    "# La función devuelve el resultado inmediatamente cuando se llama \n",
    "exponente (4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1371d83-6626-4ab0-9d5c-b4d43f2cd4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delayed('lazy_exponent-d2324939-8cd3-490a-beeb-d7dc6336f32d')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask\n",
    "\n",
    "@dask.delayed\n",
    "def lazy_exponent(x, y):\n",
    "    '''Definir una función de evaluación perezosa''' \n",
    "    return x ** y\n",
    "# La función devuelve un objeto retrasado, no un cálculo \n",
    "lazy_exponent(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f1ba178-5ff7-4d61-93c7-26ab7b666fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Esto ahora devolverá el cálculo \n",
    "\n",
    "lazy_exponent(4,5).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c37bae-e592-4163-a715-1bbc36c296ca",
   "metadata": {},
   "source": [
    "Podemos tomar este conocimiento y expandirlo, debido a que nuestra función perezosa devuelve un objeto, podemos asignarlo y luego encadenarlo de diferentes maneras más adelante.\n",
    "\n",
    "Aquí devolvemos un valor retrasado de la primera función y lo llamamos x.\n",
    "\n",
    "Luego pasamos x a la función por segunda vez y la llamamos y.\n",
    "\n",
    "Finalmente, multiplicamos x e y para producir z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7bdbc36-640c-4e4a-b21e-a617d9972ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delayed('mul-a92ba319b79bf062c5d7ddb5278f7274')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = lazy_exponent(4, 5)\n",
    "y = lazy_exponent(x, 2)\n",
    "z = x * y\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "424b8372-ccad-4b3d-9278-1ddc53679010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1073741824"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af5d594-cb24-47d2-8e5c-6e91644d6fe8",
   "metadata": {},
   "source": [
    "**Persistir vs Calcular**\n",
    "\n",
    "¿Cómo debemos indicarle a Dask que ejecute los cálculos que hemos puesto en cola con pereza? \n",
    "\n",
    "Tenemos dos opciones: *.persist()* y *.compute()*\n",
    "\n",
    "**Calcular**\n",
    "\n",
    "Si usamos **.compute()**, le estamos pidiendo a Dask que tome todos los cálculos y ajustes a los datos que hemos puesto en cola, los ejecute y los traiga a la superficie aquí.\n",
    "\n",
    "Eso significa que si se distribuyó, queremos convertirlo en un objeto local aquí y ahora.\n",
    "\n",
    "Si es un marco de datos de Dask, cuando llamamos .compute(), decimos \"Ejecute las transformaciones que hemos puesto en cola y conviértalo en un marco de datos de pandas de inmediato\".\n",
    "\n",
    "*Sin embargo, tenga cuidado: si su conjunto de datos es extremadamente grande, esto podría significar que no tendrá suficiente memoria para completar esta tarea, ¡y su kernel podría bloquearse!*\n",
    "\n",
    "**Persistir**\n",
    "\n",
    "Si usamos **.persist()**, le estamos pidiendo a Dask que tome todos los cálculos y ajustes a los datos que hemos puesto en cola y los ejecute, pero luego el objeto permanecerá distribuido y vivirá en el clúster (un LocalCluster si está en una máquina), no en la instancia de Jupyter u otro entorno local.\n",
    "\n",
    "Entonces, cuando hacemos esto con un Dask Dataframe, le estamos diciendo a nuestro clúster: \"Ejecute las transformaciones que hemos puesto en cola y deje esto como un Dask Dataframe distribuido\".\n",
    "\n",
    "Entonces, si desea procesar todas las tareas retrasadas que ha aplicado a un objeto Dask, cualquiera de estos métodos lo hará. La diferencia es dónde vivirá su objeto al final.\n",
    "\n",
    "Comprender esto es realmente útil para saber cuándo **.persist()** podría tener sentido.\n",
    "\n",
    "Considere una situación en la que carga datos y luego los usa para muchas tareas complejas.\n",
    "\n",
    "Si usa un Dask Dataframe cargado desde CSV en el disco, es posible que desee llamar **.persist()** antes de pasar estos datos a otras tareas, ya que las otras tareas ejecutarán la carga de datos una y otra vez cada vez que se refieran a ellos.\n",
    "\n",
    "Si usa **.persist()** primero, entonces el paso de carga debe ejecutarse solo una vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bafe634-5e09-461c-a16b-a0d28a083e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Delayed('add-598fdc90-48f1-47c0-b9d0-30f71ebcaf71'), Delayed('add-c6d45f8e-ec7f-4fd0-afa6-1def45db7b26'), Delayed('add-7a128c3b-b535-480e-ba48-f4032390f97c'), Delayed('add-060553c4-a909-454d-9029-d496003fb786'), Delayed('add-477cf7ed-9353-4f4a-8e86-3f8e8b92a20a')]\n",
      "4\n",
      "7\n",
      "10\n",
      "13\n",
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask\n",
    "import numpy as np\n",
    "from dask import delayed\n",
    "\n",
    "@dask.delayed\n",
    "def inc(x):\n",
    "    return x + 1\n",
    "\n",
    "@dask.delayed\n",
    "def double(x):\n",
    "    return x * 2\n",
    "\n",
    "@dask.delayed\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "data = [1, 2, 3, 4, 5]\n",
    "\n",
    "output = []\n",
    "for x in data:\n",
    "    a = inc(x)\n",
    "    b = double(x)\n",
    "    c = add(a, b)\n",
    "    output.append(c)\n",
    "\n",
    "print(output)\n",
    "print(output[0].compute())\n",
    "print(output[1].compute())\n",
    "print(output[2].compute())\n",
    "print(output[3].compute())\n",
    "print(output[4].compute())\n",
    "\n",
    "total = dask.delayed(sum)(output)\n",
    "total.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "379cad94-925c-4008-8a74-56f45cd78da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_square_function(x):\n",
    "    return x**2\n",
    "\n",
    "delayed_square_function = delayed(my_square_function)\n",
    "\n",
    "delayed_square_function(4).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e7eb7cc-623a-49bf-8bd4-81cbd379972a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uso de los resultados de un decorator delayed()\n",
    "result_delayed = delayed(my_square_function)(4)\n",
    "\n",
    "((4 + result_delayed) * 5).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28782305-fe48-4d33-b3e5-5e07eaacadba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27268"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_list = [30, 85, 14, 12, 27, 62, 89, 15, 78,  0]\n",
    "\n",
    "sum_of_squares = 0\n",
    "\n",
    "for x in x_list:\n",
    "    \n",
    "    sum_of_squares += delayed(my_square_function)(x)\n",
    "\n",
    "sum_of_squares.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aec7e5b-32a1-4f23-a3f7-09b230a4086a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to percentage\n",
      "Delayed('fraction_to_percent-8075248f-fcfa-4d25-8b56-3e5fbfc37742')\n",
      "0.3\n"
     ]
    }
   ],
   "source": [
    "def fraction_to_percent(x):\n",
    "     percentage = x * 100\n",
    "     print('Converting to percentage')\n",
    "     return x\n",
    "\n",
    "frac = 0.3\n",
    "percentage = delayed(fraction_to_percent)(frac)\n",
    "computed_percentage = percentage.compute()\n",
    "\n",
    "print(percentage)\n",
    "print(computed_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c26c1b2b-5db9-48be-9d1f-d970c3b889c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13032\n"
     ]
    }
   ],
   "source": [
    "costs_week_1 = [121, 729, 441, 961, 841, 729, 25, 225, 256, 441, 400, 484, 900]\n",
    "costs_week_2 = [196,361,81,441,49,100,729,841,676,256,121,576,49,100,49,16,961,36,841]\n",
    "\n",
    "sum1 = delayed(np.sum)(costs_week_1)\n",
    "sum2 = delayed(np.sum)(costs_week_2)\n",
    "\n",
    "total = sum1 + sum2\n",
    "\n",
    "print(total.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff613307-51c5-4e42-a5c2-9255caa9a863",
   "metadata": {},
   "source": [
    "**¿Cuáles son los diferentes planificadores en Python?**\n",
    "\n",
    "Dask le permite usar procesamiento paralelo o subprocesos múltiples.\n",
    "\n",
    "Cada uno de estos tiene sus ventajas y desventajas, y cuál funciona mejor dependerá de su tarea.\n",
    "\n",
    "Afortunadamente, Dask facilita el cambio entre ellos, por lo que puede probar ambos, pero para ganar rendimiento, es importante conocer las características de ambos.\n",
    "\n",
    "Importante el concepto de GIL (bloqueo de intérprete global de python), en palabras simples, permite que solo un subproceso tenga el control del intérprete de python.\n",
    "\n",
    "Esto significa que solo un subproceso puede estar en estado de ejecución en cualquier momento. El impacto de la GIL no es visible para los desarrolladores que ejecutan programas de subproceso único, pero puede ser un cuello de botella en el rendimiento en el código de subprocesos múltiples y vinculado a la CPU.\n",
    "\n",
    "Dado que GIL permite que solo se ejecute un subproceso a la vez, incluso en una arquitectura de subprocesos múltiples con más de un núcleo de CPU, GIL se ha ganado la reputación de ser una característica \"infame\" de Python.\n",
    "\n",
    "https://realpython.com/python-gil/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747487dc-fe4b-4e0e-81a2-6743cbf917da",
   "metadata": {},
   "source": [
    "**Subprocesos múltiples** : Un subproceso es una entidad dentro de un proceso que se puede programar para su ejecución. Además, es la unidad de procesamiento más pequeña que se puede realizar en un SO (Sistema Operativo)\n",
    "\n",
    "https://www.geeksforgeeks.org/multithreading-python-set-1/?ref=lbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c384f1b6-21bf-4800-a838-86b633370ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square: 100\n",
      "Cube: 1000\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "def print_cube(num):\n",
    "    print(\"Cube: {}\" .format(num * num * num))\n",
    "  \n",
    "def print_square(num):\n",
    "    print(\"Square: {}\" .format(num * num))\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    \n",
    "    t1 = threading.Thread(target=print_square, args=(10,))\n",
    "    t2 = threading.Thread(target=print_cube, args=(10,))\n",
    " \n",
    "    t1.start()\n",
    "    t2.start()\n",
    " \n",
    "    t1.join()\n",
    "    t2.join()\n",
    " \n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da249d0b-cb64-48c6-a4a9-b458fa201c41",
   "metadata": {},
   "source": [
    "**Procesamiento en paralelo** : El multiprocesamiento se refiere a la capacidad de un sistema para admitir más de un procesador al mismo tiempo. Las aplicaciones en un sistema de multiprocesamiento se dividen en rutinas más pequeñas que se ejecutan de forma independiente. El sistema operativo asigna estos hilos a los procesadores mejorando el rendimiento del sistema.\n",
    "\n",
    "https://www.geeksforgeeks.org/multiprocessing-python-set-2/?ref=lbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da57b473-587d-4490-a8a4-718391f69b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "  \n",
    "def print_cube(num):\n",
    "    \"\"\"\n",
    "    function to print cube of given num\n",
    "    \"\"\"\n",
    "    print(\"Cube: {}\".format(num * num * num))\n",
    "  \n",
    "def print_square(num):\n",
    "    \"\"\"\n",
    "    function to print square of given num\n",
    "    \"\"\"\n",
    "    print(\"Square: {}\".format(num * num))\n",
    "  \n",
    "if __name__ == \"__main__\":\n",
    "    #Para crear un proceso, creamos un objeto de la clase Proceso.\n",
    "    #Toma los siguientes argumentos:\n",
    "    #target : la función a ser ejecutada por el proceso\n",
    "    #args : los argumentos que se pasarán a la función de destino\n",
    "    \n",
    "    #En el ejemplo anterior, creamos 2 procesos con diferentes funciones objetivo:\n",
    "    p1 = multiprocessing.Process(target=print_square, args=(10, ))\n",
    "    p2 = multiprocessing.Process(target=print_cube, args=(10, ))\n",
    "  \n",
    "    #Para iniciar un proceso, usamos el método de start()\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "  \n",
    "    #Una vez que se inician los procesos, el programa actual también sigue ejecutándose.\n",
    "    #Para detener la ejecución del programa actual hasta que se complete un proceso,\n",
    "    #usamos el método de unión.\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "  \n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626512d3-5e95-450d-a405-2c3bc982da69",
   "metadata": {},
   "source": [
    "**Objetos de datos distribuidos**\n",
    "\n",
    "Hay otra área de trabajo de la que debemos hablar, además de retrasar las funciones individuales: estos son los objetos de datos de Dask.\n",
    "\n",
    "Estos incluyen la bolsa Dask (un objeto paralelo basado en listas), la matriz Dask (un objeto paralelo basado en matrices NumPy) y el Dask Dataframe (un objeto paralelo basado en pandas Dataframes).\n",
    "\n",
    "Para mostrar lo que estos objetos pueden hacer, discutiremos el Dask Dataframe.\n",
    "\n",
    "Imagine que tenemos los mismos datos durante varios años y nos gustaría cargarlos todos a la vez.\n",
    "\n",
    "Podemos hacerlo fácilmente con Dask, y la API es muy parecida a la API de pandas.\n",
    "\n",
    "Un marco de datos de Dask contiene varios marcos de datos de pandas, que se distribuyen en su clúster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9953086b-1a88-4231-b2ed-6abe792bb025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=30</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01</th>\n",
       "      <td>int32</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-02</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-31</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: make-timeseries, 30 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                   id    name        x        y\n",
       "npartitions=30                                 \n",
       "2000-01-01      int32  object  float64  float64\n",
       "2000-01-02        ...     ...      ...      ...\n",
       "...               ...     ...      ...      ...\n",
       "2000-01-30        ...     ...      ...      ...\n",
       "2000-01-31        ...     ...      ...      ...\n",
       "Dask Name: make-timeseries, 30 tasks"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "\n",
    "df = dask.datasets.timeseries()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "215eed47-52b2-4460-bcb2-31a05ba0850f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dask Series Structure:\n",
       "npartitions=1\n",
       "    float64\n",
       "        ...\n",
       "Name: x, dtype: float64\n",
       "Dask Name: sqrt, 157 tasks"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df[df.y > 0]\n",
    "df3 = df2.groupby('name').x.std()\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210bd4bd-b756-4d51-b6d7-f794fdf23aa1",
   "metadata": {},
   "source": [
    "Esto nos devuelve no una serie de pandas, sino una serie de Dask.\n",
    "\n",
    "Tiene una partición aquí, por lo que no se divide entre diferentes trabajadores. \n",
    "\n",
    "Es bastante pequeño, así que esto está bien para nosotros.\n",
    "\n",
    "¿Qué pasa si corremos *.compute()* con esto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccc06e24-8bf3-4aa8-b69d-1b05828bb9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computed_df = df3.compute()\n",
    "type(computed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5976108-c186-4616-baf8-8469d92d7d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Alice      0.577623\n",
       "Bob        0.576359\n",
       "Charlie    0.575616\n",
       "Dan        0.578138\n",
       "Edith      0.576330\n",
       "Name: x, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db6bf4c-ccc5-4e4a-9a07-6c9baa40a3b9",
   "metadata": {},
   "source": [
    "Volvamos al objeto df que usamos en el ejemplo anterior.\n",
    "\n",
    "Aquí vamos a usar la *npartitions* propiedad para verificar en cuántas partes se divide nuestro marco de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fca41bdf-3b5f-452e-8181-20889d425c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d14621e-154f-4111-be9d-3cd658b89931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df[df.y > 0]\n",
    "df3 = df2.groupby('name').x.std()\n",
    "print(type(df3))\n",
    "df3.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99c9dcbe-d6be-48ac-91a1-1e8c0b6073da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = df3.repartition(npartitions=3)\n",
    "df4.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e660fd4-7e36-49fc-a613-256c4250a16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dask Series Structure:\n",
       "npartitions=3\n",
       "    float64\n",
       "        ...\n",
       "        ...\n",
       "        ...\n",
       "Name: x, dtype: float64\n",
       "Dask Name: repartition, 161 tasks"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2ce000d-ea05-4132-b777-668c4a54c329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 830 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dask Series Structure:\n",
       "npartitions=3\n",
       "    float64\n",
       "        ...\n",
       "        ...\n",
       "        ...\n",
       "Name: x, dtype: float64\n",
       "Dask Name: repartition, 3 tasks"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df4.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6155abb-22f1-4204-bc00-5a327cc62023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 798 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "name\n",
       "Alice      0.577623\n",
       "Bob        0.576359\n",
       "Charlie    0.575616\n",
       "Dan        0.578138\n",
       "Edith      0.576330\n",
       "Name: x, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df4.compute().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f95acdc-5ff8-4536-b9a5-8f60bd36d258",
   "metadata": {},
   "source": [
    "**Conclusión**\n",
    "\n",
    "¡Con eso, tienes los conceptos básicos que necesitas para usar Dask!\n",
    "\n",
    "   - Su código personalizado se puede hacer paralelizable con **dask.delayed**\n",
    "\n",
    "   - El ecosistema de Dask tiene un sólido soporte nativo para las funcionalidades de pandas, NumPy y scikit-learn, lo que les brinda capacidad de paralelización.\n",
    "\n",
    "   - Los objetos de datos de Dask pueden hacer que sus datos se distribuyan, evitando problemas con demasiados datos o muy poca memoria.\n",
    "    \n",
    "Al combinar estas excelentes funciones, puede producir canalizaciones de datos potentes y de calidad de producción con las mismas API que usamos para pandas, NumPy y scikit-learn. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
