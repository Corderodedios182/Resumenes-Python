{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63d95f93-6aba-478f-91d0-5914999403ee",
   "metadata": {},
   "source": [
    "# Introducción a Spark SQL en Python\n",
    "\n",
    "1. Pyspark SQL.\n",
    "\n",
    "2. Uso de la función de ventana sql para el procesamiento del lenguaje natural.\n",
    "\n",
    "3. Almacenamiento en caché, registro y la interfaz de usuario de Spark.\n",
    "\n",
    "4. Clasificación de Texto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2c79c6-3827-4ee9-b572-56ae7b951afa",
   "metadata": {},
   "source": [
    "Apache Spark es un marco informático para el procesamiento de grandes datos. \n",
    "\n",
    "Spark SQL es un componente de Apache Spark que funciona con datos tabulares.\n",
    "\n",
    "Las funciones de ventana son una característica avanzada de SQL que llevan a Spark a un nuevo nivel de utilidad.\n",
    "\n",
    "Utilizará Spark SQL para analizar series temporales.\n",
    "\n",
    "Extraerás las secuencias de palabras más comunes de un documento de texto.\n",
    "\n",
    "Creará conjuntos de funciones a partir de texto en lenguaje natural y los usará para predecir la última palabra de una oración mediante la regresión logística.\n",
    "\n",
    "Spark combina el poder de la computación distribuida con la facilidad de uso de Python y SQL.\n",
    "\n",
    "El curso utiliza un conjunto de datos de texto en lenguaje natural que es fácil de entender.\n",
    "\n",
    "Las oraciones son secuencias de palabras.\n",
    "\n",
    "Las funciones de ventana son muy adecuadas para manipular datos de secuencia.\n",
    "\n",
    "Las mismas técnicas que se enseñan aquí se pueden aplicar a secuencias de identificadores de canciones, identificadores de video o identificadores de podcast.\n",
    "\n",
    "Los ejercicios incluyen el descubrimiento de secuencias de palabras frecuentes y la conversión de secuencias de palabras en datos de conjuntos de funciones de aprendizaje automático para entrenar un clasificador de texto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c40aedd-6197-45f5-a530-fcf276c554e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import broadcast\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f77669ed-4700-472e-8d44-81dd3153ea36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-N6L95A43:4044\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f77309bf-545c-4f5f-99b7-df2be199f13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+-----+--------+\n",
      "|train_id|      station| time|diff_min|\n",
      "+--------+-------------+-----+--------+\n",
      "|     217|       Gilroy|6:06a|     9.0|\n",
      "|     217|   San Martin|6:15a|     6.0|\n",
      "|     217|  Morgan Hill|6:21a|    15.0|\n",
      "|     217| Blossom Hill|6:36a|     6.0|\n",
      "|     217|      Capitol|6:42a|     8.0|\n",
      "|     217|       Tamien|6:50a|     9.0|\n",
      "|     217|     San Jose|6:59a|    null|\n",
      "|     324|San Francisco|7:59a|     4.0|\n",
      "|     324|  22nd Street|8:03a|    13.0|\n",
      "|     324|     Millbrae|8:16a|     8.0|\n",
      "|     324|    Hillsdale|8:24a|     7.0|\n",
      "|     324| Redwood City|8:31a|     6.0|\n",
      "|     324|    Palo Alto|8:37a|    28.0|\n",
      "|     324|     San Jose|9:05a|    null|\n",
      "+--------+-------------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"Datos/trainsched.txt\", header=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3f229b77-2088-4690-b9de-fb26f87858c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"schedule\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f0a208-3fac-4ead-93bc-e972be31b68c",
   "metadata": {},
   "source": [
    "#### Uso de Lenguaje SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4a78e4de-febe-40db-bf79-1a49ff10c2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-------+\n",
      "|col_name|data_type|comment|\n",
      "+--------+---------+-------+\n",
      "|train_id|   string|   null|\n",
      "| station|   string|   null|\n",
      "|    time|   string|   null|\n",
      "|diff_min|   string|   null|\n",
      "+--------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE schedule\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e78cfb62-0d2d-416c-8beb-c7cbce6ba7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-----+--------+\n",
      "|train_id| station| time|diff_min|\n",
      "+--------+--------+-----+--------+\n",
      "|     217|San Jose|6:59a|    null|\n",
      "|     324|San Jose|9:05a|    null|\n",
      "+--------+--------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM schedule WHERE station LIKE '%San Jose%'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6667623-3b6a-4aea-a17b-d2891aac6012",
   "metadata": {},
   "source": [
    "#### Funciones de Ventanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0fde5e79-da0b-44a5-8d7d-3485fd8ea782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+-----+--------+-------------+\n",
      "|train_id|      station| time|diff_min|running_total|\n",
      "+--------+-------------+-----+--------+-------------+\n",
      "|     217|       Gilroy|6:06a|     9.0|          9.0|\n",
      "|     217|   San Martin|6:15a|     6.0|         15.0|\n",
      "|     217|  Morgan Hill|6:21a|    15.0|         30.0|\n",
      "|     217| Blossom Hill|6:36a|     6.0|         36.0|\n",
      "|     217|      Capitol|6:42a|     8.0|         44.0|\n",
      "|     217|       Tamien|6:50a|     9.0|         53.0|\n",
      "|     217|     San Jose|6:59a|    null|         53.0|\n",
      "|     324|San Francisco|7:59a|     4.0|          4.0|\n",
      "|     324|  22nd Street|8:03a|    13.0|         17.0|\n",
      "|     324|     Millbrae|8:16a|     8.0|         25.0|\n",
      "|     324|    Hillsdale|8:24a|     7.0|         32.0|\n",
      "|     324| Redwood City|8:31a|     6.0|         38.0|\n",
      "|     324|    Palo Alto|8:37a|    28.0|         66.0|\n",
      "|     324|     San Jose|9:05a|    null|         66.0|\n",
      "+--------+-------------+-----+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT train_id, station, time, diff_min,\n",
    "SUM(diff_min) OVER (PARTITION BY train_id ORDER BY time) AS running_total\n",
    "FROM schedule\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4dd457b0-d72e-4cf2-a274-7f541a409a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------------+-----+---------+\n",
      "|row|train_id|      station| time|time_next|\n",
      "+---+--------+-------------+-----+---------+\n",
      "|  1|     217|       Gilroy|6:06a|    6:15a|\n",
      "|  2|     217|   San Martin|6:15a|    6:21a|\n",
      "|  3|     217|  Morgan Hill|6:21a|    6:36a|\n",
      "|  4|     217| Blossom Hill|6:36a|    6:42a|\n",
      "|  5|     217|      Capitol|6:42a|    6:50a|\n",
      "|  6|     217|       Tamien|6:50a|    6:59a|\n",
      "|  7|     217|     San Jose|6:59a|    7:59a|\n",
      "|  8|     324|San Francisco|7:59a|    8:03a|\n",
      "|  9|     324|  22nd Street|8:03a|    8:16a|\n",
      "| 10|     324|     Millbrae|8:16a|    8:24a|\n",
      "| 11|     324|    Hillsdale|8:24a|    8:31a|\n",
      "| 12|     324| Redwood City|8:31a|    8:37a|\n",
      "| 13|     324|    Palo Alto|8:37a|    9:05a|\n",
      "| 14|     324|     San Jose|9:05a|     null|\n",
      "+---+--------+-------------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "ROW_NUMBER() OVER (ORDER BY time) AS row,\n",
    "train_id, \n",
    "station, \n",
    "time, \n",
    "LEAD(time,1) OVER (ORDER BY time) AS time_next \n",
    "FROM schedule\n",
    "\"\"\"\n",
    "spark.sql(query).show()\n",
    "\n",
    "# Dar el número de la fila mala como un número entero\n",
    "bad_row = 7\n",
    "\n",
    "# Proporcione la cláusula que falta, palabras clave de SQL en mayúsculas\n",
    "clause = 'PARTITION BY train_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c418ac-9621-4dcc-8e72-7f1f49466386",
   "metadata": {},
   "source": [
    "#### Funciones de Agregación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d297b5ce-a6d5-482c-953b-8f2d65020841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|train_id|start|\n",
      "+--------+-----+\n",
      "|     217|6:06a|\n",
      "|     324|7:59a|\n",
      "+--------+-----+\n",
      "\n",
      "+--------+-----+\n",
      "|train_id|start|\n",
      "+--------+-----+\n",
      "|     217|6:06a|\n",
      "|     324|7:59a|\n",
      "+--------+-----+\n",
      "\n",
      "+--------+---------+---------+\n",
      "|train_id|min(time)|max(time)|\n",
      "+--------+---------+---------+\n",
      "|     217|    6:06a|    6:59a|\n",
      "|     324|    7:59a|    9:05a|\n",
      "+--------+---------+---------+\n",
      "\n",
      "+--------+---------+\n",
      "|train_id|max(time)|\n",
      "+--------+---------+\n",
      "|     217|    6:59a|\n",
      "|     324|    9:05a|\n",
      "+--------+---------+\n",
      "\n",
      "max(time)\n"
     ]
    }
   ],
   "source": [
    "# Give the identical result in each command\n",
    "spark.sql('SELECT train_id, MIN(time) AS start FROM schedule GROUP BY train_id').show()\n",
    "df.groupBy('train_id').agg({'time':'min'}).withColumnRenamed('min(time)', 'start').show()\n",
    "\n",
    "# Print the second column of the result\n",
    "spark.sql('SELECT train_id, MIN(time), MAX(time) FROM schedule GROUP BY train_id').show()\n",
    "result = df.groupBy('train_id').agg({'time':'min', 'time':'max'})\n",
    "result.show()\n",
    "print(result.columns[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9dc27059-f981-4d44-8e7f-ef61b3ef0d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-----+\n",
      "|train_id|start|  end|\n",
      "+--------+-----+-----+\n",
      "|     217|6:06a|6:59a|\n",
      "|     324|7:59a|9:05a|\n",
      "+--------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write a SQL query giving a result identical to dot_df\n",
    "query = \"SELECT train_id, MIN(time) AS start, MAX(time) AS end FROM schedule GROUP BY train_id\"\n",
    "sql_df = spark.sql(query)\n",
    "sql_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c0f86429-3933-4485-b394-a56d6706c121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+-----+--------+---------+\n",
      "|train_id|      station| time|diff_min|time_next|\n",
      "+--------+-------------+-----+--------+---------+\n",
      "|     217|       Gilroy|6:06a|     9.0|    6:15a|\n",
      "|     217|   San Martin|6:15a|     6.0|    6:21a|\n",
      "|     217|  Morgan Hill|6:21a|    15.0|    6:36a|\n",
      "|     217| Blossom Hill|6:36a|     6.0|    6:42a|\n",
      "|     217|      Capitol|6:42a|     8.0|    6:50a|\n",
      "|     217|       Tamien|6:50a|     9.0|    6:59a|\n",
      "|     217|     San Jose|6:59a|    null|     null|\n",
      "|     324|San Francisco|7:59a|     4.0|    8:03a|\n",
      "|     324|  22nd Street|8:03a|    13.0|    8:16a|\n",
      "|     324|     Millbrae|8:16a|     8.0|    8:24a|\n",
      "|     324|    Hillsdale|8:24a|     7.0|    8:31a|\n",
      "|     324| Redwood City|8:31a|     6.0|    8:37a|\n",
      "|     324|    Palo Alto|8:37a|    28.0|    9:05a|\n",
      "|     324|     San Jose|9:05a|    null|     null|\n",
      "+--------+-------------+-----+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "# Obtain the identical result using dot notation \n",
    "dot_df = df.withColumn('time_next', lead('time', 1)\n",
    "        .over(Window.partitionBy('train_id')\n",
    "        .orderBy('time')))\n",
    "\n",
    "dot_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
